<!DOCTYPE html> <html lang="cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 手把手搭建 BP 神经网络 | Geek F. x </title> <meta name="author" content="Geek F. x"> <meta name="description" content=""> <meta name="keywords" content="academic-website, portfolio-website, geek, geekfx, geekjkfx, jkfx, blog, computer-science, deep-learning, AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon/favicon_blue/favicon.ico?88a93ea07c0a82656ab29388cee125af"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://jkfx.github.io/blog/2020/%E6%89%8B%E6%8A%8A%E6%89%8B%E6%90%AD%E5%BB%BA-BP-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Geek</span> F. x </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <style>img{width:100%}</style> <div class="post"> <header class="post-header"> <h1 class="post-title">手把手搭建 BP 神经网络</h1> <p class="post-meta"> Created in November 16, 2020 </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="neural-networks">Neural networks</h2> <h3 id="visualizing-the-data">Visualizing the data</h3> <blockquote> <p>数据集来自 <a href="https://www.kaggle.com/gpreda/chinese-mnist" rel="external nofollow noopener" target="_blank">https://www.kaggle.com/gpreda/chinese-mnist</a></p> </blockquote> <p>在这一部分，首先需要加载数据并随机输出几个图像。</p> <p>加载的数据有 \(15000\) 个训练样本（training examples），每一个训练样本是一个 \(64\times 64\) 像素的灰度图。每一个像素代表了一个 \(8\) 位的无符号整数，代表了每个位置的灰度强度。这 \(64\times 64\) 的像素网格将被展开成为一个 \(4096\) 维的向量。这些训练样本将会成为矩阵 \(X\) 的每一行。所以维度为 \(15000\times 4096\) 的矩阵。</p> \[X=\begin{bmatrix} -(x^{(1)})^T-\\ -(x^{(2)})^T-\\ \vdots \\ -(x^{(m)})^T-\\ \end{bmatrix}\] <p>第二部分，是一个 \(15000\) 维的向量 \(y\) 其包含了所有训练集的标签。其值是从 \(1\) 到 \(15\) 分别表示汉字：零、一、二、三、四、五、六、七、八、九、十、百、千、万、亿。</p> <p>并且将加载的数据集按照 \(7:3\) 的比例分成两个集合：训练集（training set）、测试集（test set）。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">image</span> <span class="k">as</span> <span class="n">img</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">os</span> <span class="kn">import</span> <span class="n">listdir</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">optimize</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">openpyxl</span>
<span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="n">scipy</span> <span class="kn">import</span> <span class="n">io</span>
<span class="kn">import</span> <span class="n">re</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span> <span class="o">=</span> <span class="mi">64</span> <span class="o">*</span> <span class="mi">64</span>  <span class="c1"># 特征数量
</span><span class="n">m</span> <span class="o">=</span> <span class="mi">15000</span>  <span class="c1"># 数据样本数量
</span><span class="n">input_layer_size</span> <span class="o">=</span> <span class="n">n</span>  <span class="c1"># 64 * 64 的灰度图像
</span><span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">256</span>  <span class="c1"># 256 个隐藏单元
</span><span class="n">num_labels</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># 15 个分类
</span><span class="n">Lambda</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># 正则化系数
</span></code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">read_images</span><span class="p">(</span><span class="n">dir_str</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
    <span class="n">files_list</span> <span class="o">=</span> <span class="nf">listdir</span><span class="p">(</span><span class="n">dir_str</span><span class="p">)</span>
    <span class="n">files_str</span> <span class="o">=</span> <span class="nf">str</span><span class="p">(</span><span class="n">files_list</span><span class="p">)</span>
    <span class="c1"># 样本数量
</span>    <span class="n">m</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">files_list</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_labels</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="sh">'</span><span class="s">input_\d*_\d*_</span><span class="sh">'</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">+</span> <span class="sh">'</span><span class="s">\.jpg</span><span class="sh">'</span>
        <span class="n">label_list</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">findall</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">files_str</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">label_list</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="n">label</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">count</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">dir_str</span> <span class="o">+</span> <span class="nb">file</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">data</span>
    

<span class="n">dir_str</span> <span class="o">=</span> <span class="sh">'</span><span class="s">./data/</span><span class="sh">'</span>
<span class="n">data</span> <span class="o">=</span> <span class="nf">read_images</span><span class="p">(</span><span class="n">dir_str</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># 子图为 3 行，5 列
</span><span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">axe</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axe</span><span class="p">:</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="nf">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)),</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div> <p><img src="https://tvax3.sinaimg.cn/large/006VTcCxly1gkxuhrqr1ij30a806udg7.jpg" alt="output_4_0"></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Xy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">),</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">Xytest</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">),</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_labels</span><span class="p">):</span>
    <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">Xy</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">),</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">),</span> <span class="p">:]</span>
    <span class="n">Xy</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">)</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Xytest</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">)</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">)</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">),</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.7</span><span class="p">):,</span> <span class="p">:]</span>
    <span class="n">Xytest</span><span class="p">[</span><span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">)</span> <span class="p">:</span> <span class="n">i</span> <span class="o">*</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">)</span> <span class="o">+</span> <span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">m</span> <span class="o">//</span> <span class="n">num_labels</span> <span class="o">*</span> <span class="mf">0.3</span><span class="p">))</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">Xy</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">Xytest</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">Xy</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">Xy</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Xtest</span> <span class="o">=</span> <span class="n">Xytest</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="n">Xytest</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mat</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nf">loadmat</span><span class="p">(</span><span class="sh">'</span><span class="s">ex4data2.mat</span><span class="sh">'</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">X</span><span class="sh">'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">Xtest</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">Xtest</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">ytest</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ytest</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">ytest</span><span class="p">)</span>
</code></pre></div></div> <h3 id="model-representation">Model representation</h3> <p>神经网络如下图所示：</p> <p><img src="https://tva2.sinaimg.cn/large/006VTcCxly1gkedhveav1j30ny0k0n2b.jpg" alt="neural notworks"></p> <p>共有 \(3\) 层， \(1\) 个输入层， \(1\) 个隐层， \(1\) 个输出层。</p> <p>每张图片共有 \(64\times 64\) 个像素，所以输入层有 \(4096\) 个输入单元，每个隐层有 \(256\) 个单元，输出层为 \(15\) 个输出单元，表示 \(15\) 个类别的个数。</p> <h3 id="feedforward-and-cost-function">Feedforward and cost function</h3> <p>神经网络的带有正则化项的损失函数（cost function with regularization）表示为：</p> \[J(\theta)=\frac{1}{m} \sum_{i=1}^{m}\sum_{k=1}^{K}\left[-y_k^{(i)}log((h_\theta (x^{(i)})))_k-(1-y_k^{(i)})log(1-(h_\theta (x^{(i)})))_k\right]+\frac{\lambda }{2m} \left[\sum_{j=1}^{256}\sum_{k=1}^{4096}(\Theta^{(1)}_{j,k})^2+\sum_{j=1}^{15}\sum_{k=1}^{256}(\Theta^{(2)}_{j,k})^2\right]\] <p>其中，\(h_\theta(x^{(i)})\) 表示向神经网络输入计算后的输出， \(K=15\) 表示所有可能的标签的个数， \(h_\theta(x^{(i)})_k=a_k^{(3)}\) 表示第 \(k\) 个输出单元的激励值（activation），并且不对偏置单元（bias unit）进行正则化。</p> <p>除此之外，模型的原始标签值是 \(1,2,\dots,15\) 的整数，为了训练神经网络，需要将这些十进制的整数值重新编码为只有 \(0\) 和 \(1\) 的标签向量：</p> \[y= \begin{bmatrix} 1\\ 0\\ 0\\ \vdots \\ 0 \end{bmatrix}, \begin{bmatrix} 0\\ 1\\ 0\\ \vdots \\ 0 \end{bmatrix},\dots, \begin{bmatrix} 0\\ 0\\ 0\\ \vdots \\ 1 \end{bmatrix}\] <p>假设 \(x^{(i)}\) 表示汉字“五”的图片，那么对应的 \(y^{(i)}\) 应该是一个 \(15\) 维的向量，并且 \(y_5=1\) 其它元素都等于 \(0\) 。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">nnCostFun</span><span class="p">(</span><span class="n">nn_params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">input_layer_size</span><span class="o">=</span><span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="o">=</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">Lambda</span><span class="o">=</span><span class="n">Lambda</span><span class="p">):</span>
    <span class="n">Theta1</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">Theta2</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:</span> <span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 样本的个数
</span>    <span class="c1"># 将样本标签转换为 15 维的 0-1 向量
</span>    <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
        <span class="n">yy</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="nf">int</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="c1"># 执行前向传播
</span>    <span class="c1"># 给 X 增加 1 列，全为 1
</span>    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">uint</span><span class="p">)</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span><span class="n">a1</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
    <span class="c1"># 前向传播
</span>    <span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">Theta1</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
    <span class="c1"># 增加第二层（隐藏层）的偏置单元
</span>    <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">a2</span><span class="p">))</span>
    <span class="n">z3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">Theta2</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>  <span class="c1"># m * num_labels
</span>    <span class="c1"># 计算 J
</span>    <span class="n">s</span> <span class="o">=</span> <span class="o">-</span><span class="n">yy</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">a3</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">-=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">yy</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a3</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>  <span class="c1"># 计算每个输出单元的累加
</span>    <span class="n">J</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">s</span><span class="p">;</span>
    <span class="c1"># 正则化 J
</span>    <span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">power</span><span class="p">(</span><span class="n">Theta1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">power</span><span class="p">(</span><span class="n">Theta2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">t1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">t2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>
    <span class="n">J</span> <span class="o">+=</span> <span class="p">(</span><span class="n">Lambda</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">))</span> <span class="o">*</span> <span class="n">s</span>
    <span class="c1"># 反向传播计算梯度
</span>    <span class="n">delta3</span> <span class="o">=</span> <span class="n">a3</span> <span class="o">-</span> <span class="n">yy</span>
    <span class="n">delta2</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">delta3</span><span class="p">,</span> <span class="n">Theta2</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">*</span> <span class="nf">sigmoid_gradient</span><span class="p">(</span><span class="n">z2</span><span class="p">))</span>
    <span class="n">Theta1_grad</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">delta2</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">a1</span><span class="p">)</span>
    <span class="n">Theta2_grad</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">delta3</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">a2</span><span class="p">)</span>
    <span class="c1"># 正则化 D
</span>    <span class="n">Theta1_grad</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">Lambda</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">Theta2_grad</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">+=</span> <span class="p">(</span><span class="n">Lambda</span> <span class="o">/</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">Theta2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">Theta1_grad</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">).</span><span class="nf">tolist</span><span class="p">(),</span> <span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">Theta2_grad</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()]</span>
    <span class="n">gradient</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">gradient</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">J</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">costFun</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">nnCostFun</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
</code></pre></div></div> <h2 id="backpropagation">Backpropagation</h2> <p>在这一部分，我们实现后 BP 算法计算神经网络的损失函数的梯度（gradient）。</p> <h3 id="sigmoid-gradient">Sigmoid gradient</h3> <p>首先，我们实现 Sigmoid 函数的梯度：</p> \[sigmoid(z)=g(z)=\frac{1}{1+e^{-z}}\] \[{g}'(z)=\frac{\mathrm{d}}{\mathrm{d}z} g(z)=g(z)(1-g(z))\] <p>对于预测的越准确的激励值， \(z\) 的值也就越大，梯度就越趋向于 \(0\) 。当 \(z=0\) 时，梯度的值应该正好是 \(0.25\) 。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">sigmoid_gradient</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>
</code></pre></div></div> <h3 id="random-initialization">Random initialization</h3> <p>当开始训练网络之前，随机初始化每一个参数用来对称破缺（symmetry breaking）是非常重要的。一个随机初始化非常有效的策略是，随机地为 \(\Theta^{(l)}\) 选择一个在统一 \(\left[-\epsilon_{init},\epsilon_{init}\right]\) 范围内的值。我们可以使用 \(\epsilon_{init}=0.12\) 。这个范围保证了参数保持在一个非常小的值，并使得学习更加有效。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">randInitialize</span><span class="p">(</span><span class="n">L_in</span><span class="p">,</span> <span class="n">L_out</span><span class="p">):</span>
    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">0.12</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="n">L_out</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">L_in</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">epsilon</span> <span class="o">-</span> <span class="n">epsilon</span>
    <span class="k">return</span> <span class="n">W</span>
</code></pre></div></div> <h3 id="back-propagation">Back-propagation</h3> <p>给定一个训练样本 \((x^{(t)}, y^{(t)})\) ，首先输入神经网络并前向传播计算神经网络所有的激励值，包括输出值 \(h_\Theta(x)\) 。然后，对于第 \(l\) 层的结点 \(j\) ，将通过测量结点对于任何误差的“负责度”（responsible），计算误差项（error item） \(\delta_j^{(l)}\) 。</p> <p>对于一个输出结点，可以直接通过测量神经网络的激励值与真实的目标值的差值，并使用其定义 \(\delta_j^{(3)}\) 。对于隐藏单元，将基于第 \((l+1)\) 层的结点的误差项的加权平均值去计算 \(\delta_j^{(l)}\) 。</p> <ol> <li>对于第 \(t\) 个训练样本 \(x^{(t)}\) ，设置输入层的值 \(a^{(1)}\) 。执行前向传播，计算每层的激励值 \((z^{(2)},a^{(2)},z^{(3)},a^{(3)})\) 。每一层都需要增加一个 \(+1\) 项的偏置单元。</li> <li>对于第 \(3\) 层的输出单元 \(k\) ，设 \(\delta_k^{(3)}=(a_k^{(3)}-y_k)\)</li> <li>对于隐藏层 \(l=2\) ，设 \(\delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}.*{g}'(z^{(2)})\)</li> <li>使用如下公式积累神经网络的梯度值： \(\Delta^{(l)}=\Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T\) 注意，此步骤不对偏置单元 \(\delta_0^{(l)}\) 进行计算。</li> <li>将通过使用累积的梯度除以 \(m\) 得到神经网络的损失函数的梯度： \(\frac{\partial}{\partial\Theta^{(l)}_{ij}}J(\Theta)=D^{(l)}_{ij}=\frac{1}{m}\Delta^{(l)}_{ij}\)</li> </ol> <h3 id="gradient-checking">Gradient checking</h3> <p>可以将参数矩阵 \(\Delta\) 展开成为一个非常长的向量 \(\theta\) 。通过这样做，可以将损失函数看作 \(J(\theta)\) 并使用下面的步骤进行梯度检查。</p> <p>假设有一个函数 \(f_i(\theta)\) 去计算 \(\frac{\partial}{\partial\theta_i}J(\theta)\) 检查 \(f_i\) 是否输出了正确的导数值。设</p> \[\theta^{(i+)}=\theta+\begin{bmatrix} 0\\ 0\\ \vdots\\ \epsilon\\ \vdots\\ 0 \end{bmatrix} \ and\ \theta^{(i-)}=\theta-\begin{bmatrix} 0\\ 0\\ \vdots\\ \epsilon\\ \vdots\\ 0 \end{bmatrix}\] <p>因此， \(\theta^{(i+)}\) 除了第 \(i\) 个元素的值被增加了 \(\epsilon\) 其它值都与 \(\theta\) 的值相同，与之类似地， \(\theta^{(i-)}\) 也是除了第 \(i\) 个元素被减少了 \(\epsilon\) 其余的值都与 \(\theta\) 相同。可以使用数值验证对于每一个 \(i\) 的 \(f_i(\theta)\) 的正确性：</p> \[f_i(\theta)\approx\frac{J(\theta^{(i+)})-J(\theta^{(i-)})}{2\epsilon}\] <p>这两个值彼此的接近程度将取决于 \(J\) 的细节。假设 \(\epsilon=1e^{-4}\) ，通常将会发现上面左手和右手边的式子至少接受 \(4\) 位有效数字。</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">numericalGradient</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">in_lay</span><span class="p">,</span> <span class="n">hidden_lay</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">):</span>
    <span class="n">numgrad</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">theta</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">perturb</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">theta</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="n">theta</span><span class="p">)):</span>
        <span class="c1"># 设置扰动向量
</span>        <span class="n">perturb</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="n">e</span>
        <span class="n">loss1</span> <span class="o">=</span> <span class="nf">nnCostFun</span><span class="p">(</span><span class="n">theta</span> <span class="o">-</span> <span class="n">perturb</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">in_lay</span><span class="p">,</span> <span class="n">hidden_lay</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
        <span class="n">loss1</span> <span class="o">=</span> <span class="n">loss1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">loss2</span> <span class="o">=</span> <span class="nf">nnCostFun</span><span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">perturb</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">in_lay</span><span class="p">,</span> <span class="n">hidden_lay</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
        <span class="n">loss2</span> <span class="o">=</span> <span class="n">loss2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># 计算数值解梯度
</span>        <span class="n">numgrad</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss2</span> <span class="o">-</span> <span class="n">loss1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">e</span><span class="p">)</span>
        <span class="n">perturb</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">numgrad</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">checkGradient</span><span class="p">(</span><span class="n">Lambda</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="c1"># 测试数据
</span>    <span class="n">in_lay</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">hidden_lay</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">num</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">mm</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="c1"># 生成参数和样本
</span>    <span class="n">Theta1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">hidden_lay</span> <span class="o">*</span> <span class="p">(</span><span class="n">in_lay</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">Theta2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_lay</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">Theta1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">Theta1</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">hidden_lay</span><span class="p">,</span> <span class="n">in_lay</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Theta2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">Theta2</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">hidden_lay</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">mm</span> <span class="o">*</span> <span class="n">in_lay</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">X</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="n">mm</span><span class="p">,</span> <span class="n">in_lay</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="p">.</span><span class="nf">mod</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">mm</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="p">)</span>
    <span class="c1"># 展开参数
</span>    <span class="n">pars</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">Theta1</span><span class="p">).</span><span class="nf">tolist</span><span class="p">(),</span> <span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">Theta2</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()]</span>
    <span class="n">pars</span> <span class="o">=</span> <span class="n">pars</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">pars</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">pars</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">pars</span><span class="p">)</span>
    <span class="c1"># 分别计算梯度
</span>    <span class="n">grad</span> <span class="o">=</span> <span class="nf">nnCostFun</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">in_lay</span><span class="p">,</span> <span class="n">hidden_lay</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
    <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">numgrad</span> <span class="o">=</span> <span class="nf">numericalGradient</span><span class="p">(</span><span class="n">pars</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">in_lay</span><span class="p">,</span> <span class="n">hidden_lay</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">)</span>
    <span class="c1"># 计算差的范数
</span>    <span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">numgrad</span> <span class="o">-</span> <span class="n">grad</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">numgrad</span> <span class="o">+</span> <span class="n">grad</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">diff</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">checkGradient</span><span class="p">()</span>
</code></pre></div></div> <h2 id="regularized-neural-networks">Regularized Neural Networks</h2> <p>增加一个正则化项到梯度上，在使用反向传播计算完 \(\Delta_{ij}^{(l)}\) 之后，使用如下公式对梯度正则化：</p> \[\frac{\partial}{\partial\Theta^{(l)}_{ij}}J(\Theta)=D^{(l)}_{ij}=\frac{1}{m}\Delta^{(l)}_{ij}\ \ for\ j=0\] \[\frac{\partial}{\partial\Theta^{(l)}_{ij}}J(\Theta)=D^{(l)}_{ij}=\frac{1}{m}\Delta^{(l)}_{ij}+\frac{\lambda}{m}+\Theta^{(l)}_{ij}\ \ for\ j\ge1\] <p>注意不会对 \(\Theta^{(l)}\) 的第一列的偏置项进行正则化。</p> <h3 id="learning-parameters">Learning parameters</h3> <p>在成功地实现了神经网络的损失函数和梯度的计算之后，下一步走将会使用优化函数学习一个良好的参数集。</p> <h4 id="minibatch-stochasitc-gradient-descent">Minibatch Stochasitc Gradient Descent</h4> <p>按照数据生成分布抽取 \(m\) 个小批量（独立同分布的）样本，通过计算它们的梯度均值，可以得到梯度的无偏估计。</p> <p>\(SGD\) 及相关的小批量亦或更广义的基于梯度优化的在线学习算法，一个重要的性质是每一步更新的计算时间不依赖训练样本数目的多寡。即使训练样本非常大时，它们也能收敛。对于足够大的数据集， \(SGD\) 可能会在处理整个训练集之前就收敛到最终测试误差的某个固定容差范围内。</p> <p>在求数值解的优化算法中，先选取一组模型参数的初始值，如随机选取；接下来对参数进行多次迭代，使每次迭代都可能降低损失函数的值。在每次迭代中，先随机均匀采样一个由固定数目训练数据样本所组成的小批量（mini-batch）\(\mathcal{B}\)，然后求小批量中数据样本的平均损失有关模型参数的导数（梯度），最后用此结果与预先设定的一个正数的乘积作为模型参数在本次迭代的减小量。</p> <p>模型的每个参数将作如下迭代：</p> \[\Theta^{(l)}_{ij}=\Theta^{(l)}_{ij}-\frac{\alpha}{\left|\mathcal{B}\right|}\sum_{i\in\mathcal{B}}\frac{\partial}{\partial\Theta^{(l)}_{ij}}J(\Theta)=\Theta^{(l)}_{ij}-\frac{\alpha}{\left|\mathcal{B}\right|}\sum_{i\in\mathcal{B}}D^{(l)}_{ij}\] <table> <tbody> <tr> <td>在上式中，$$</td> <td>\mathcal{B}</td> <td>\(代表每个小批量中的样本个数（批量大小，batch size），\)\alpha$$称作学习率（learning rate）并取正数。</td> </tr> </tbody> </table> <h5 id="vectorized">Vectorized</h5> <p>在模型训练或预测时，常常会同时处理多个数据样本并用到矢量计算。</p> <p>广义上讲，当数据样本数为\(m\)，特征数为\(n\)时，矢量计算表达式为</p> \[h_\theta(X)=\hat{y}=Xw+b\] <p>其中模型输出 \(\hat{y}\in\mathbb{R}^{m\times1}\) ， 批量数据样本特征 \(X\in\mathbb{R}^{m\times n}\) ，权重 \(w\in\mathbb{R}^{n\times 1}\) ， 偏差 \(b \in \mathbb{R}\) 。相应地，批量数据样本标签 \(\boldsymbol{y} \in \mathbb{R}^{\mathcal{B} \times 1}\) 。设模型参数 \(\boldsymbol{\theta}\) ，我们可以重写损失函数为</p> \[J(\theta)=\ell(\boldsymbol{\theta})=\frac{1}{2n}(\boldsymbol{\hat{y}}-\boldsymbol{y})^\top(\boldsymbol{\hat{y}}-\boldsymbol{y}).\] <p>小批量随机梯度下降的迭代步骤将相应地改写为</p> \[\boldsymbol{\theta} \leftarrow \boldsymbol{\theta} - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \nabla_{\boldsymbol{\theta}} \ell^{(i)}(\boldsymbol{\theta}),\] <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">unroll</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">):</span>
    <span class="n">Theta1</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">Theta2</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:</span> <span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Theta1</span><span class="p">,</span> <span class="n">Theta2</span>

<span class="k">def</span> <span class="nf">roll</span><span class="p">(</span><span class="n">Theta1</span><span class="p">,</span> <span class="n">Theta2</span><span class="p">):</span>
    <span class="n">l</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">Theta1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">).</span><span class="nf">tolist</span><span class="p">(),</span> <span class="n">np</span><span class="p">.</span><span class="nf">ravel</span><span class="p">(</span><span class="n">Theta2</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">).</span><span class="nf">tolist</span><span class="p">()]</span>
    <span class="n">l</span> <span class="o">=</span> <span class="n">l</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">l</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">Theta1</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">Theta2</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:</span> <span class="p">].</span><span class="nf">reshape</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># 样本的个数
</span>    <span class="c1"># 执行前向传播
</span>    <span class="c1"># 给 X 增加 1 列，全为 1
</span>    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span><span class="n">a1</span><span class="p">,</span> <span class="n">X</span><span class="p">))</span>
    <span class="c1"># 前向传播
</span>    <span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="n">Theta1</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
    <span class="c1"># 增加第二层（隐藏层）的偏置单元
</span>    <span class="n">ones</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span><span class="n">ones</span><span class="p">,</span> <span class="n">a2</span><span class="p">))</span>
    <span class="n">z3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">a2</span><span class="p">,</span> <span class="n">Theta2</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>  <span class="c1"># m * num_labels
</span>    <span class="k">return</span> <span class="n">a3</span>
    
<span class="k">def</span> <span class="nf">predict_accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="c1"># 预测、计算准确率
</span>    <span class="n">pre</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">a3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">pre</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>

<span class="k">def</span> <span class="nf">predict_graph</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">pre</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">a3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
    <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">labels</span><span class="p">:</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">pre</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">accuracies</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">accuracies</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">mgd</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">maxepoch</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">epoch_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cost_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_accuracy_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c1"># cost
</span>    <span class="n">fig1</span><span class="p">,</span> <span class="n">axes1</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
    <span class="c1"># accuracy
</span>    <span class="n">fig2</span><span class="p">,</span> <span class="n">axes2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">maxepoch</span><span class="p">):</span>
        <span class="c1"># 小批量进行更新全部训练集一次
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
            <span class="n">XX</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">yy</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
            <span class="n">J</span><span class="p">,</span> <span class="n">grad</span> <span class="o">=</span> <span class="nf">nnCostFun</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">XX</span><span class="p">,</span> <span class="n">yy</span><span class="p">)</span>
            <span class="c1"># 更新参数
</span>            <span class="n">params</span> <span class="o">-=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grad</span>
        <span class="c1"># 记录
</span>        <span class="n">epoch_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
        <span class="n">cost_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>
        <span class="n">test_accuracy</span> <span class="o">=</span> <span class="nf">predict_accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
        <span class="n">test_accuracy_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">test_accuracy</span><span class="p">)</span>
        <span class="n">train_accuracy</span> <span class="o">=</span> <span class="nf">predict_accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">train_accuracy_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="n">train_accuracy</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">)</span>
    <span class="n">axes1</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">cost_list</span><span class="p">)</span>
    <span class="n">axes1</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">epoch</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes1</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">cost</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes1</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">J</span><span class="p">,</span> <span class="sh">'</span><span class="s">learning rate: %f</span><span class="sh">'</span> <span class="o">%</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">axes2</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">test_accuracy_list</span><span class="p">)</span>
    <span class="n">axes2</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">epoch_list</span><span class="p">,</span> <span class="n">train_accuracy_list</span><span class="p">)</span>
    <span class="n">axes2</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">epoch</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes2</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">axes2</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">,</span> <span class="sh">'</span><span class="s">learning rate: %f</span><span class="sh">'</span> <span class="o">%</span><span class="n">learning_rate</span><span class="p">)</span>
    <span class="n">axes2</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">test accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">train accuracy</span><span class="sh">'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># 图例
</span>    <span class="n">fig1</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">cost_</span><span class="sh">'</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">())))</span>
    <span class="n">fig2</span><span class="p">.</span><span class="nf">savefig</span><span class="p">(</span><span class="sh">'</span><span class="s">accuracy_</span><span class="sh">'</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="nf">int</span><span class="p">(</span><span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">())))</span>
    <span class="k">return</span> <span class="n">cost_list</span><span class="p">,</span> <span class="n">test_accuracy_list</span><span class="p">,</span> <span class="n">train_accuracy_list</span>
</code></pre></div></div> <p>不同的学习速率、正则化项对学习曲线（learning curve）的表现形式都有所不同</p> <p>下面对三个不同的学习速率进行简单的测试，可以看到不同的学习速率对梯度下降的性能是有着非常大的影响的；一个经常的方法是在迭代中逐渐修改学习速率，可以较好避免噪声对迭代的影响。</p> <p><img src="https://tvax2.sinaimg.cn/large/006VTcCxly1gkvgmtsy2mj30w00c0753.jpg" alt="learning curve"></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mat</span> <span class="o">=</span> <span class="n">io</span><span class="p">.</span><span class="nf">loadmat</span><span class="p">(</span><span class="sh">'</span><span class="s">ex4weights2.mat</span><span class="sh">'</span><span class="p">)</span>
<span class="n">Theta1</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">Theta1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">Theta2</span> <span class="o">=</span> <span class="n">mat</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sh">'</span><span class="s">Theta2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="nf">roll</span><span class="p">(</span><span class="n">Theta1</span><span class="p">,</span> <span class="n">Theta2</span><span class="p">)</span>
</code></pre></div></div> <p>在执行完小批量的梯度下降后，可以看到训练集的准确率为 \(96\%\) ， 每个数字的准确率如条形图所示</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">predict_graph</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">predict_accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <p><img src="https://tvax4.sinaimg.cn/large/006VTcCxly1gkxuhxubj0j30af06wq2r.jpg" alt="output_27_1"></p> <p>测试集的准确率为 \(70\%\) ，对于非二分类的问题，这里是十五个类别，\(70\%\) 的准确率不算太低</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">predict_graph</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
<span class="nf">predict_accuracy</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>
</code></pre></div></div> <p><img src="https://tva2.sinaimg.cn/large/006VTcCxly1gkxui29earj30af06wmwz.jpg" alt="output_29_1"></p> <p>下面从测试集中随机抽取 \(10\) 张图片进行识别，查看效果</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">label_map</span> <span class="o">=</span> <span class="p">{</span><span class="mi">1</span><span class="p">:</span><span class="sh">'</span><span class="s">零</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="sh">'</span><span class="s">一</span><span class="sh">'</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span><span class="sh">'</span><span class="s">二</span><span class="sh">'</span><span class="p">,</span> <span class="mi">4</span><span class="p">:</span><span class="sh">'</span><span class="s">三</span><span class="sh">'</span><span class="p">,</span> <span class="mi">5</span><span class="p">:</span><span class="sh">'</span><span class="s">四</span><span class="sh">'</span><span class="p">,</span> <span class="mi">6</span><span class="p">:</span><span class="sh">'</span><span class="s">五</span><span class="sh">'</span><span class="p">,</span> <span class="mi">7</span><span class="p">:</span><span class="sh">'</span><span class="s">六</span><span class="sh">'</span><span class="p">,</span> <span class="mi">8</span><span class="p">:</span><span class="sh">'</span><span class="s">七</span><span class="sh">'</span><span class="p">,</span> <span class="mi">9</span><span class="p">:</span><span class="sh">'</span><span class="s">八</span><span class="sh">'</span><span class="p">,</span> <span class="mi">10</span><span class="p">:</span><span class="sh">'</span><span class="s">九</span><span class="sh">'</span><span class="p">,</span> <span class="mi">11</span><span class="p">:</span><span class="sh">'</span><span class="s">十</span><span class="sh">'</span><span class="p">,</span> <span class="mi">12</span><span class="p">:</span><span class="sh">'</span><span class="s">百</span><span class="sh">'</span><span class="p">,</span> <span class="mi">13</span><span class="p">:</span><span class="sh">'</span><span class="s">千</span><span class="sh">'</span><span class="p">,</span> <span class="mi">14</span><span class="p">:</span><span class="sh">'</span><span class="s">万</span><span class="sh">'</span><span class="p">,</span> <span class="mi">15</span><span class="p">:</span><span class="sh">'</span><span class="s">亿</span><span class="sh">'</span><span class="p">}</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">axe</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axe</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4500</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">Xtest</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reshape</span><span class="p">((</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">label_map</span><span class="p">.</span><span class="nf">get</span><span class="p">((</span><span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:].</span><span class="nf">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">)).</span><span class="nf">argmax</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">end</span><span class="o">=</span><span class="sh">'</span><span class="s">  </span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><img src="https://tva1.sinaimg.cn/large/006VTcCxly1gkxuiblhzaj30a805v0sv.jpg" alt="output_32_1"></p> <p>可以看到仍然有些误差，这是非常正常的，因为此模型选用的 \(BP\) 神经网络，对于这种图像识别的，使用卷积神经网络才是非常有力的模型。</p> <p>下面可以使用 Photoshop 软件创建一个 \(64\times 64\) 的灰度图，并在图里手写一个汉字数字，然后放到神经网络里进行识别</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ttt</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">tt.jpg</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">ttt</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">gray</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pp</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">ttt</span><span class="p">.</span><span class="nf">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span> <span class="n">order</span><span class="o">=</span><span class="sh">'</span><span class="s">F</span><span class="sh">'</span><span class="p">))</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">pp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nf">print</span><span class="p">(</span><span class="n">label_map</span><span class="p">[</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
</code></pre></div></div> <p><img src="https://tva2.sinaimg.cn/large/006VTcCxly1gkxuigcvivj306z06z0sk.jpg" alt="output_35_1"></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Ubuntu-22.04-%E5%AE%89%E8%A3%85-MySQL/">Ubuntu 22.04 安装 MySQL</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Clean-Architecture/">Clean Architecture</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/Ubuntu-22.04-MacOS-Monterey-%E4%B8%BB%E9%A2%98/">LaTeX Workshop 配置信息</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/CASIA-WebMaskedFace-%E6%A8%A1%E6%8B%9F%E4%BD%A9%E6%88%B4%E5%8F%A3%E7%BD%A9%E4%BA%BA%E8%84%B8%E6%95%B0%E6%8D%AE%E9%9B%86/">CASIA-WebMaskedFace 模拟佩戴口罩人脸数据集</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/LaTeX-Workshop-%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF/">LaTeX Workshop 配置信息</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Geek F. x. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>